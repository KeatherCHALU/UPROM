# -*- coding: utf-8 -*-
"""UP-ROM TEST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SUJ36zwUqQO_RrOCBk78dIeRUZ4puX-l
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt
import os

class VariationalEncoder(keras.Model):
  # On crée une classe pour le VAE

  def __init__(self,latent_dim,param_dim,input_shape_phi,name="variational_encoder",**kwargs):
    super().__init__(name=name,**kwargs) #Appel constructeur keras.Model
    self.latent_dim=latent_dim #Attribut taille de compression
    self.param_dim=param_dim #Attribut taille du vecteur paramètre
    self.input_shape_phi=input_shape_phi #Attribut taille de l'entrée

    #Extraction des caractéristiques des données via un réseau convolutif
    self.encoder_body=keras.Sequential([
        layers.InputLayer(input_shape=self.input_shape_phi),
        layers.Conv2D(32,(3,3),activation="relu",strides=2,padding="same"),
        layers.Conv2D(64,(3,3),activation="relu",strides=2,padding="same"),
        layers.Conv2D(128,(3,3),activation="relu",strides=2,padding="same"),
        layers.Flatten(),
        layers.Dense(256,activation="relu")
    ],name="encoder_body")

    self.merge_layer=layers.Concatenate(name="merge_phi_xi")#Concaténation de la dynamique avec les paramètres
    self.post_merge_dense=layers.Dense(128,activation="relu",name="post_merge_dense")#Extraction des caractéristiques

    #Sorties pour la moyenne et le log variance
    self.fc_mean=layers.Dense(latent_dim,name="fc_mean")
    self.fc_log_var=layers.Dense(latent_dim,name="fc_log_var")

  def call(self,inputs):
    #Appel du VAE

    #Vérification de la forme des données
    if not isinstance(inputs,(list,tuple)) or len(inputs) !=2:
      raise ValueError("l'entrée doit être une liste ou un tuple de deux tenseurs [phi_t,xi]")

    phi_t,xi=inputs
    phi_features=self.encoder_body(phi_t) #Passage de nos données dans l'encodeur
    merged_features=self.merge_layer([phi_features,xi]) #On rajoute les paramètres
    hidden=self.post_merge_dense(merged_features) #On mélange

    #sortie pour la moyenne et le log variance
    mu=self.fc_mean(hidden)
    log_var=self.fc_log_var(hidden)

    return mu,log_var

  def reparameterize(self,mu,log_var):

    #Nécessaire pour la rétropropagation du VAE
    std=tf.exp(0.5*log_var)
    epsilon=tf.random.normal(shape=tf.shape(std))

    return mu+epsilon*std

  def get_config(self):

    #Récupération de la configuration du modèle
    config=super().get_config()
    config.update({"latent_dim":self.latent_dim,"param_dim": self.param_dim,"input_shape_phi":self.input_shape_phi})
    return config

class CustomTransformerBlock(layers.Layer):
  #On crée une classe pour le block du transformer, ma version de Keras n'a pas de tranformer par défaut

  def __init__(self,embed_dim,num_heads,feed_forward_dim,dropout=0.1,**kwargs):
    super().__init__(**kwargs) #Appel du constructeur de layers.Layer
    self.embed_dim=embed_dim#Attribut pour la dimension du plongement
    self.num_heads=num_heads#Attribut pour le nombre de tête d'attention
    self.feed_forward_dim=feed_forward_dim#Attribut pour la Feed-Forward pour suivre l'attention

    #Création du bloc d'attention multitêtes
    self.mha=layers.MultiHeadAttention(
        num_heads=num_heads,
        key_dim=embed_dim,
        dropout=dropout
    )

    #Création du bloc feed-forward
    self.ffn=keras.Sequential([
        layers.Dense(feed_forward_dim,activation="relu"),layers.Dense(embed_dim)
    ])

    self.layernorm1=layers.LayerNormalization(epsilon=1e-6)#Normalisation après l'attention
    self.layernorm2=layers.LayerNormalization(epsilon=1e-6)#Normalisation après le feed-forward
    self.dropout1=layers.Dropout(dropout)#Dropout pour éviter le surapprentissage après l'attention
    self.dropout2=layers.Dropout(dropout)#Dropout pour éviter le surapprentissage après le feed-forward

  def call(self,inputs,training=False):
    #Appel du Transformer

    attn_output=self.mha(inputs,inputs)#Auto-attention pour comprendre les relations
    attn_output=self.dropout1(attn_output,training=training)#Dropout au niveau de la sortie de l'attention
    out1=self.layernorm1(inputs+attn_output)#Permet d'éviter la disparition du gradient

    ffn_output=self.ffn(out1)#Passage de la sortie dans le feed-forward
    ffn_output=self.dropout2(ffn_output,training=training)#Dropout à la sortie du feed-forward
    out2=self.layernorm2(out1+ffn_output)#Permet d'éviter la disparition du gradient

    return out2

  def get_config(self):
    #Récupération de la configuration
    config=super().get_config()
    config.update({
        "embed_dim":self.embed_dim,
        "num_heads":self.num_heads,
        "feed_forward_dim":self.feed_forward_dim
    })
    return config

class LatentTransformer(keras.Model):
  #On crée une classe pour le transformer

  def __init__(self,
               latent_dim,
               hidden_dim,
               num_heads,
               num_blocks,
               param_dim,
               sequence_length,
               name="latent_transformer",
               **kwargs):

    super().__init__(name=name,**kwargs)#Appel du constructeur keras.Model
    self.latent_dim=latent_dim#Attribut pour la dimension de l'espace latent
    self.hidden_dim=hidden_dim#Attribut pour la dimension du tranformer
    self.num_heads=num_heads#Attribut pour le nombre de tête d'attention
    self.num_blocks=num_blocks#Attribut pour le nombre de bloc/profondeur
    self.param_dim=param_dim#Attribut pour le nombre de paramètres
    self.sequence_length=sequence_length#Attribut de la fenêtre temporelle

    self.input_projection=layers.Dense(hidden_dim,name="input_projection")#Projection des entrée pour le transformer
    self.param_projection=layers.Dense(hidden_dim,name="param_projection")#Projection des paramètres pour le transformer

    self.positional_embedding=layers.Embedding(input_dim=sequence_length,
                                               output_dim=hidden_dim,
                                               name="positional_embedding")#Plongement de la position des données

    self.transformer_blocks=[] #Création d'une liste vide pour remplir d'instances de CustomTransformer
    for i in range(num_blocks):
      block=CustomTransformerBlock(embed_dim=hidden_dim,
                                                  num_heads=num_heads,
                                                  feed_forward_dim=hidden_dim*4,
                                                  dropout=0.1,
                                                  name=f"transformer_block_{i}")
      self.transformer_blocks.append(block)

    self.output_head=layers.Dense(latent_dim,
                                  name="output_head")#Compression de la sortie

  def call(self,inputs):
    #Appel du transformer latent

    if not isinstance(inputs,(list,tuple)) or len(inputs) !=2:
      raise ValueError("L'entrée du LatentTransformer doit être une liste ou un tuple"
      "de deux tenseurs : [z_sequence,xi]") #Vérification des données en entrée

    z_sequence,xi=inputs #trajectoire,paramètres

    z_projected=self.input_projection(z_sequence)#Projection de la trajectoire

    xi_projected=self.param_projection(xi)#Projection des paramètres
    xi_expanded=tf.expand_dims(xi_projected,1)#Pour copier les paramètres directement à travers les pas temporels

    positions=tf.range(start=0,limit=self.sequence_length,delta=1)#Indices de longueur de notre fenêtre temporelle
    pos_embeddings=self.positional_embedding(positions)#Projection des positions

    x=z_projected+xi_expanded+pos_embeddings#Combinaison de toutes les données projetées

    for block in self.transformer_blocks:
      x=block(x) #analyse de nos données par le transformer

    x_last=x[:,-1,:]#On récupère la dernière sortie

    z_t_plus_1_hat=self.output_head(x_last) #Compression de la sortie

    return z_t_plus_1_hat

  def get_config(self):
    #Récupération de la configuration actuelle
    config=super().get_config()
    config.update({
        "latent_dim": self.latent_dim,
        "hidden_dim": self.hidden_dim,
        "num_heads": self.num_heads,
        "num_blocks":self.num_blocks,
        "param_dim":self.param_dim,
        "sequence_length":self.sequence_length
    })
    return config

class Decoder(keras.Model):

  def __init__(self,latent_dim,param_dim,output_shape_phi,name="decoder",**kwargs):

    super().__init__(name=name,**kwargs)#Appel du constructeur de Keras.Model
    self.latent_dim=latent_dim#Attribut pour la dimension latente
    self.param_dim=param_dim#Attribut pour la dimension de l'espace des paramètres
    self.output_shape_phi=output_shape_phi#Attribut pour la taille de la sortie

    self.merge_layer=layers.Concatenate(name="merge_z_xi")#Concaténation de la dynamique et des paramètres

    self.initial_dense_dim=17*13*128 #Paramètres d'expansion obtenus d'après la table 3, et un pas de 2 pour 3 couches
    self.initial_dense=layers.Dense(self.initial_dense_dim,activation="relu") #Expansion des données
    self.reshape_layer=layers.Reshape((17,13,128))#Passage des données vecteur en tenseur

    #On empile les couches de transformation par déconvolution en faisant du upsampling
    self.decoder_body=keras.Sequential([
        layers.Conv2DTranspose(128,(3,3),strides=2,padding="same",activation="relu"),
        layers.Conv2DTranspose(64,(3,3),strides=2,padding="same",activation="relu"),
        layers.Conv2DTranspose(32,(3,3),strides=2,padding="same",activation="relu"),
        layers.Conv2DTranspose(output_shape_phi[-1],(3,3),padding="same",activation="linear"),
        layers.Resizing(output_shape_phi[0],output_shape_phi[1])
    ],name="decoder_body")#On récupère des données de la même taille que nos entrées


  def call(self,inputs):
    #Appel le décodeur

    if not isinstance(inputs,(list,tuple)) or len(inputs) !=2:
      raise ValueError("Inputs must be [z_t,xi]")#Vérification des entrées

    z_t,xi=inputs#Vecteur latent et paramètres

    x=self.merge_layer([z_t,xi])#Concaténation des deux

    x=self.initial_dense(x)
    x=self.reshape_layer(x)#Passage en tenseur

    reconstruction=self.decoder_body(x)#Retour des données finales déconvoluées

    return reconstruction

  def get_config(self):
    #Récupération de la configuration
    config=super().get_config()
    config.update({
        "latent_dim":self.latent_dim,
        "param_dim": self.param_dim,
        "output_shape_phi":self.output_shape_phi
    })
    return config

class UP_ROM(keras.Model):
  #Classe pour le modèle UPROM

  def __init__(self,
               latent_dim,
               hidden_dim,
               num_heads,
               num_blocks,
               param_dim,
               input_shape_phi,
               lookback_window,
               prediction_horizon,
               lambda_reg=100.0,
               beta_reg=1e-4,
               **kwargs):

    super().__init__(**kwargs)#Appel le constructeur des classes nécessaires


    self.latent_dim=latent_dim#Attribut pour la dimension de l'espace latent
    self.hidden_dim=hidden_dim#Attribut pour la dimension du transformer
    self.num_heads=num_heads#Nombre de têtes d'attention
    self.num_blocks=num_blocks#Nombre de blocs/profondeur
    self.param_dim=param_dim#Nombre de paramètres
    self.input_shape_phi=input_shape_phi#Taille de la dynamique
    self.lookback_window=lookback_window #Fenêtre temporelle arrière
    self.prediction_horizon=prediction_horizon #Horizon de prédiction
    self.lambda_reg=lambda_reg#lambda
    self.beta_reg=beta_reg#beta

    self.q=lookback_window#Raccourci de notation pour la fenêtre temporelle
    self.h=prediction_horizon#Raccourci de notation pour l'horizon de prédiction

    #Instancie la l'encodeur variationnel pour la compression
    self.encoder=VariationalEncoder(
        latent_dim=latent_dim,
        param_dim=param_dim,
        input_shape_phi=input_shape_phi,
        name="encoder"
    )

    #Instancie le transformer pour la prédiction
    self.transformer=LatentTransformer(
        latent_dim=latent_dim,
        hidden_dim=hidden_dim,
        num_heads=num_heads,
        num_blocks=num_blocks,
        param_dim=param_dim,
        sequence_length=lookback_window,
        name="transformer"
    )

    #Instancie le décodeur pour la reconstruction
    self.decoder=Decoder(
        latent_dim=latent_dim,
        param_dim=param_dim,
        output_shape_phi=input_shape_phi,
        name="decoder"
    )

    #Initialisation des métriques pour surveiller la perte
    self.total_loss_tracker=keras.metrics.Mean(name="total_loss")
    self.recon_loss_tracker=keras.metrics.Mean(name="recon_loss")
    self.kld_loss_tracker=keras.metrics.Mean(name="kld_loss")
    self.pred_loss_tracker=keras.metrics.Mean(name="pred_loss")

  #Définition de la métrique à utiliser
  @property
  def metrics(self):
    return [
        self.total_loss_tracker,
        self.recon_loss_tracker,
        self.kld_loss_tracker,
        self.pred_loss_tracker
    ]

  def call(self,inputs):
    #Appel de la classe UPROM

    phi_past,xi=inputs#Dynamique et paramètres
    batch_size=tf.shape(phi_past)[0]#Récupération de la taille des données
    z_list=[]#Liste vide pour la trajectoire latente

    #Boucle sur les temps passées pour analyser
    for t in range(self.q):
      mu,log_var=self.encoder([phi_past[:,t],xi])#Récupération de la moyenne et le log-variance
      z_t=self.encoder.reparameterize(mu,log_var)#Récupération du vecteur latent
      z_list.append(z_t)

    z_sequence=tf.stack(z_list,axis=1)#Création du vecteur contenant la trajectoire
    predictions_phi=[]#Liste pour contenir la prédiction
    curr_z_seq=z_sequence#Séquence à considérer pour le transformer

    #Boucle sur le futur pour prédire
    for k in range(self.h):
      z_next=self.transformer([curr_z_seq,xi])#Application du transformer pour prédire la suite de la trajectoire
      phi_next=self.decoder([z_next,xi])#Décompression de la donnée latente dans l'espace physique
      predictions_phi.append(phi_next)#Ajout du nouvel état physique
      z_next_expanded=tf.expand_dims(z_next,1)#On modifie le vecteur latent en un tenseur
      curr_z_seq=tf.concat([curr_z_seq[:,1:],z_next_expanded],axis=1)#On rajoute le nouveau point dans l'espace latent à notre suite et on retire le plus ancien

    return tf.stack(predictions_phi,axis=1)#Retourne les états physique prédits

  def train_step(self,data):
    #Implémentation de la fonction perte de l'article

    #Vérification du type de données
    if isinstance(data,tuple):
      data=data[0]

    phi_full,xi=data#Séquence physique passée+future et paramètres

    phi_past=phi_full[:,:self.q]#Séquence passée
    phi_future=phi_full[:,self.q:]#Séquence future

    with tf.GradientTape() as tape:#Enregistrement des opérations pour la rétropropagation
      batch_size=tf.shape(phi_past)[0]
      z_past_list=[]
      phi_past_recon_list=[]
      kld_loss_sum= 0.0

      #On étudie le comportement du VAE en calculant la perte associée

      for t in range(self.q):
        #Encodage de la séquence physique passée comme plus haut
        phi_t=phi_past[:,t]
        mu,log_var=self.encoder([phi_t,xi])
        z_t=self.encoder.reparameterize(mu,log_var)
        z_past_list.append(z_t)

        #Décodage de la séquence physique future comme plus haut
        phi_t_recon=self.decoder([z_t,xi])
        phi_past_recon_list.append(phi_t_recon)
        kld=-0.5*tf.reduce_sum(1+log_var-tf.square(mu)-tf.exp(log_var),axis=1)#Calcul du KLD
        kld_loss_sum+=tf.reduce_mean(kld)#Calcul de l'accumulation de l'erreur

      z_past_seq=tf.stack(z_past_list,axis=1)#Passage de la séquence latente passée en tenseur pour le transformer
      phi_past_recon=tf.stack(phi_past_recon_list,axis=1)#Passage la séquence physique passée en tenseur pour le transformer

      recon_loss=tf.reduce_mean(tf.square(phi_past-phi_past_recon))#Calcul de la perte de la reconstruction
      vae_loss=recon_loss+self.beta_reg*(kld_loss_sum/float(self.q))#Calcul de la perte du VAE

      #On s'intéresse au transformer maintenant

      z_future_true_list=[]#Liste vide pour la vraie trajectoire dans le latent

      #Boucle pour l'encodage de la vraie trajectoire latente
      for t in range(self.h):
        mu,log_var=self.encoder([phi_future[:,t],xi])#Moyenne et variance de la vraie trajectoire latente par encodage
        z_future_true_list.append(self.encoder.reparameterize(mu,log_var))#Échantillonage et stockage de la valeur cible
      z_future_true=tf.stack(z_future_true_list,axis=1)#Tenseur contenant la trajectoire échantillonée

      z_future_pred_list=[]#Liste pour contenir la trajectoire future prédite
      phi_future_pred_list=[]#Liste pour contenir l'état physique futur prédit
      curr_z_seq=z_past_seq#Séquence de trajectoire à considérer pour le transformer

      #Boucle auto-regressive pour prédire pas à pas la trajectoire
      for t in range(self.h):
        z_next_pred=self.transformer([curr_z_seq,xi]) #Application du transformer
        z_future_pred_list.append(z_next_pred) #Ajout du vecteur latent

        phi_next_pred=self.decoder([z_next_pred,xi])#Passage dans l'espace physique
        phi_future_pred_list.append(phi_next_pred)#Ajout du vecteur physique

        z_next_expanded=tf.expand_dims(z_next_pred,1)#Passage en tenseur
        curr_z_seq=tf.concat([curr_z_seq[:,1:],z_next_expanded],axis=1)#Glissement de la fenêtre vers la suite de la trajectoire

      z_future_pred=tf.stack(z_future_pred_list,axis=1)#Passage en tenseur
      phi_future_pred=tf.stack(phi_future_pred_list,axis=1)#Glissement de la fenêtre vers la dynamique suivante

      latent_pred_loss=tf.reduce_mean(tf.square(z_future_true-z_future_pred))#Calcul de la perte dans l'espace latent
      phys_pred_loss=tf.reduce_mean(tf.square(phi_future-phi_future_pred))#Calcul de la perte dans l'espace physique

      total_loss=self.lambda_reg*vae_loss+latent_pred_loss+phys_pred_loss#Calcul de la perte totale

    grads=tape.gradient(total_loss,self.trainable_weights)#Rétropropagation
    self.optimizer.apply_gradients(zip(grads,self.trainable_weights))#Descnete de gradient

    #Mise à jour des métriques
    self.total_loss_tracker.update_state(total_loss)
    self.recon_loss_tracker.update_state(recon_loss)
    self.kld_loss_tracker.update_state(kld_loss_sum)
    self.pred_loss_tracker.update_state(phys_pred_loss)

    return {
        "loss": self.total_loss_tracker.result(),
        "recon":self.recon_loss_tracker.result(),
        "kld":self.kld_loss_tracker.result(),
        "pred":self.pred_loss_tracker.result()
        }

    def get_config(self):
      #Récupération de la configuration

      config = super().get_config()
      config.update({
          "latent_dim": self.latent_dim,
          "hidden_dim": self.hidden_dim,
          "num_heads": self.num_heads,
          "num_blocks": self.num_blocks,
          "param_dim": self.param_dim,
          "input_shape_phi": self.input_shape_phi,
          "lookback_window": self.lookback_window,
          "prediction_horizon": self.prediction_horizon,
          "lambda_reg": self.lambda_reg,
          "beta_reg": self.beta_reg,
      })
      return config

def create_sequences(data,xi,lookback_q,prediction_h):

  #Création d'une fenêtre glissante de suites de trajectoires
  total_len=len(data)
  seq_len=lookback_q+prediction_h
  sequences=[]
  xi_list=[]

  for i in range(total_len-seq_len+1):
    seq=data[i:i+seq_len]
    sequences.append(seq)

    if len(xi.shape)==1:
      xi_list.append(xi)
    else: #Au cas où les paramètres évoluent avec le temps
      xi_list.append(xi[i])
  return np.array(sequences),np.array(xi_list)

#À remplir pour générer les données
# X_data=[]

# Paramètres
lookback_q=10
prediction_h=10

all_seq_phi=[]
all_seq_xi=[]

for i in range(len(X_data)):
    sim_phi=X_data[i]
    sim_xi=Xi_data[i]

    seq_phi,seq_xi=create_sequences(sim_phi, sim_xi,lookback_q, prediction_h)

    all_seq_phi.append(seq_phi)
    all_seq_xi.append(seq_xi)

X_train=np.concatenate(all_seq_phi, axis=0)
xi_train=np.concatenate(all_seq_xi, axis=0)

#Instanciation du modèle
uprom_test=UP_ROM(
    latent_dim=4,
    hidden_dim=64,
    num_heads=8,
    num_blocks=1,
    param_dim=2,
    input_shape_phi=(131, 100, 2),
    lookback_window=LOOKBACK_Q,
    prediction_horizon=PREDICTION_H,
    lambda_reg=100.0,
    beta_reg=1e-4
)

uprom_test.compile(optimizer=keras.optimizers.Adam(1e-3))

#Entraînement
print("Lancement de l'entraînement")
history = uprom_test.fit(
    x=[X_train,xi_train],
    batch_size=4,
    epochs=15,
    shuffle=True
)